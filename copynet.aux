\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{2}{section.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces the human language communication.For example, in the following two dialogue turns we observe differ- ent patterns in which some subsequences (colored blue) in the response (R) are copied from the input utterance (I)}}{2}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Background: Neural Models for Sequence-to-sequence Learning}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}RNN Encoder-Decoder}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}The Attention Mechanism}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}COPYNET}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model Overview}{5}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The overall diagram of COPYNET. For simplicity, we omit some links for prediction (see Sections 3.2 for more details).}}{5}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Prediction with Copying and Generation}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The illustration of the decoding probability $p(y_t|·)$ as a 4-class classifier.}}{7}{figure.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}State Update}{8}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Hybrid Addressing of M}{9}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Learning}{10}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Synthetic Dataset}{11}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  data }}{12}{figure.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Text Summarization}{12}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  result }}{13}{figure.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  TS data }}{14}{figure.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Examples of COPYNET on LCSTS compared with RNN context. Word segmentation is applied on the input, where underlined are OOV words. The highlighted words (with different colors) are those words with copy-mode probability higher than the generate-mode. We also provide literal English translation for the document, the golden, and COPYNET, while omitting that for RNN context since the language is broken. }}{15}{figure.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Single-turn Dialogue}{16}{subsection.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  Examples on the testing set of DS-II shown as the input text and golden, with the outputs of RNNSearch and CopyNet. Words in red rectangles are unseen in the training set. The highlighted words (with different colors) are those words with copy-mode probability higher than the generate-mode. Green cirles (meaning correct) and red cross (meaning incorrect) are given based on human judgment on whether the response is appropriate. }}{16}{figure.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Related Work}{16}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion and Future Work}{17}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Personal understanding}{17}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Paper structure}{17}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}The problem to solve}{17}{subsection.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Paper: COPYNET.}}{18}{figure.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Paper: COPYNET..}}{19}{figure.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces the human language communication.For example, in the following two dialogue turns we observe differ- ent patterns in which some subsequences (colored blue) in the response (R) are copied from the input utterance (I)}}{19}{figure.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The overall diagram of COPYNET.}}{20}{figure.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The illustration of the decoding probability $p(y_t|·)$ as a 4-class classifier.}}{20}{figure.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Attention-based Encoder-Decoder (RNNSearch)}}{21}{figure.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Prediction with Copying and Generation(Generate-Mode \& Copy-Mode)}}{22}{figure.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces State update}}{23}{figure.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Hybrid Addressing of M}}{24}{figure.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}The innovation work}{24}{subsection.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}The code analysis}{24}{subsection.9.4}\protected@file@percent }
\gdef \@abspage@last{24}
